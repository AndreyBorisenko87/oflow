"""
–ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ–π —Ü–µ–ø–æ—á–∫–∏ –±–ª–æ–∫–æ–≤
Scalping Strategy Pipeline
"""

import logging
from pathlib import Path
from typing import Dict, List
import yaml

from .blocks import (
    # –ë–ª–æ–∫ 02: –ò–º–ø–æ—Ä—Ç —Å—ã—Ä—å—è
    import_raw_data,
    
    # –ë–ª–æ–∫ 04: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏
    run_time_sync,
    
    # –ë–ª–æ–∫ 05: –õ—É—á—à–∏–µ —Ü–µ–Ω—ã
    run_best_prices,
    
    # –ë–ª–æ–∫ 06: –¢–æ–ø-–∑–æ–Ω–∞ –∫–Ω–∏–≥–∏
    run_book_top,
    
    # –ë–ª–æ–∫ 07: –õ–µ–Ω—Ç–∞ —Å–¥–µ–ª–æ–∫
    run_trade_tape,
    
    # –ë–ª–æ–∫ 08: –ö—Ä–æ—Å—Å-–±–∏—Ä–∂–µ–≤–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è
    run_cross_exchange,
    
    # –ë–ª–æ–∫ 09: –ë–∞–∑–∏—Å —Å–ø–æ—Ç-—Ñ—å—é—á–µ—Ä—Å
    run_basis,
    
    # –ë–ª–æ–∫ 10: –§–∏—á–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
    run_features,
    
    # –ë–ª–æ–∫ 11: –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Å–ª–æ–π
    run_canonical,
    
    # –ë–ª–æ–∫ 12: –î–µ—Ç–µ–∫—Ç–æ—Ä—ã
    run_detectors,
    
    # –ë–ª–æ–∫ 13: –°–∫–∞–Ω–µ—Ä
    run_scanner,
    
    # –ë–ª–æ–∫ 14: –ë—ç–∫—Ç–µ—Å—Ç
    run_backtest,
    
    # –ë–ª–æ–∫ 15: –≠–∫—Å–ø–æ—Ä—Ç —Ä–∞–∑–º–µ—Ç–∫–∏
    export_data
)

def setup_logging(config: Dict) -> None:
    """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    log_config = config.get("logging", {})
    
    logging.basicConfig(
        level=getattr(logging, log_config.get("level", "INFO")),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_config.get("file", "logs/oflow.log"), encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

def load_config(config_dir: str = "configs") -> Dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    config_path = Path(config_dir) / "config.yaml"
    sources_path = Path(config_dir) / "sources.yaml"
    
    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    with open(sources_path, "r", encoding="utf-8") as f:
        sources = yaml.safe_load(f)
    
    config["sources"] = sources
    return config

def run_full_pipeline(config_dir: str = "configs", test_mode: bool = True) -> Dict[str, any]:
    """
    –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    
    Args:
        config_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
        test_mode: –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤)
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞
    """
    logger = logging.getLogger(__name__)
    logger.info("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = load_config(config_dir)
    setup_logging(config)
    
    results = {}
    
    try:
        # 2. –ë–ª–æ–∫ 02: –ò–º–ø–æ—Ä—Ç —Å—ã—Ä—å—è
        logger.info("=== –ë–õ–û–ö 02: –ò–ú–ü–û–†–¢ –°–´–†–¨–Ø ===")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
        import_data = {
            "data_paths": [],
            "start_time": None,
            "end_time": None
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –∏–∑ sources.yaml
        if "sources" in config:
            sources = config["sources"]
            for market_type in ["spot", "futures"]:
                if market_type in sources:
                    for exchange in sources[market_type]:
                        for data_type in ["trades", "depth"]:
                            if data_type in sources[market_type][exchange]:
                                import_data["data_paths"].append(sources[market_type][exchange][data_type])
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(import_data['data_paths'])} –ø—É—Ç–µ–π –∫ –¥–∞–Ω–Ω—ã–º")
        
        if test_mode:
            trades_df, depth_df = import_raw_data(import_data, config)
        else:
            trades_df, depth_df = import_raw_data(import_data, config)
        
        results["import"] = {"trades": trades_df, "depth": depth_df}
        logger.info(f"–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {len(trades_df)} trades, {len(depth_df)} depth")
        
        # 3. –ë–ª–æ–∫ 04: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏
        logger.info("=== –ë–õ–û–ö 04: –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –í–†–ï–ú–ï–ù–ò ===")
        synced_trades, synced_depth = run_time_sync(trades_df, depth_df, config)
        results["sync"] = {"trades": synced_trades, "depth": synced_depth}
        logger.info("–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        # 4. –ë–ª–æ–∫ 05: –õ—É—á—à–∏–µ —Ü–µ–Ω—ã
        logger.info("=== –ë–õ–û–ö 05: –õ–£–ß–®–ò–ï –¶–ï–ù–´ ===")
        quotes_df = run_best_prices(synced_depth, config)
        results["quotes"] = quotes_df
        logger.info("–õ—É—á—à–∏–µ —Ü–µ–Ω—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
        
        # 5. –ë–ª–æ–∫ 06: –¢–æ–ø-–∑–æ–Ω–∞ –∫–Ω–∏–≥–∏
        logger.info("=== –ë–õ–û–ö 06: –¢–û–ü-–ó–û–ù–ê –ö–ù–ò–ì–ò ===")
        book_df = run_book_top(synced_depth, config)
        results["book_top"] = book_df
        logger.info("–¢–æ–ø-–∑–æ–Ω–∞ –∫–Ω–∏–≥–∏ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        
        # 6. –ë–ª–æ–∫ 07: –õ–µ–Ω—Ç–∞ —Å–¥–µ–ª–æ–∫
        logger.info("=== –ë–õ–û–ö 07: –õ–ï–ù–¢–ê –°–î–ï–õ–û–ö ===")
        tape_df = run_trade_tape(synced_trades, config)
        results["tape"] = tape_df
        logger.info("–õ–µ–Ω—Ç–∞ —Å–¥–µ–ª–æ–∫ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        
        # 7. –ë–ª–æ–∫ 08: –ö—Ä–æ—Å—Å-–±–∏—Ä–∂–µ–≤–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è
        logger.info("=== –ë–õ–û–ö 08: –ö–†–û–°–°-–ë–ò–†–ñ–ï–í–ê–Ø –ê–ì–†–ï–ì–ê–¶–ò–Ø ===")
        nbbo_df, volume_df = run_cross_exchange(quotes_df, synced_trades, config)
        results["nbbo"] = nbbo_df
        results["volume"] = volume_df
        logger.info("–ö—Ä–æ—Å—Å-–±–∏—Ä–∂–µ–≤–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
        # 8. –ë–ª–æ–∫ 09: –ë–∞–∑–∏—Å —Å–ø–æ—Ç-—Ñ—å—é—á–µ—Ä—Å
        logger.info("=== –ë–õ–û–ö 09: –ë–ê–ó–ò–° –°–ü–û–¢-–§–¨–Æ–ß–ï–†–° ===")
        # TODO: –†–∞–∑–¥–µ–ª–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ spot –∏ futures
        basis_df = run_basis(synced_trades, synced_trades, config)  # –ó–∞–≥–ª—É—à–∫–∞
        results["basis"] = basis_df
        logger.info("–ë–∞–∑–∏—Å —Å–ø–æ—Ç-—Ñ—å—é—á–µ—Ä—Å –≤—ã—á–∏—Å–ª–µ–Ω")
        
        # 9. –ë–ª–æ–∫ 10: –§–∏—á–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        logger.info("=== –ë–õ–û–ö 10: –§–ò–ß–ò –ü–ê–¢–¢–ï–†–ù–û–í ===")
        features_df = run_features(book_df, tape_df, quotes_df, config)
        results["features"] = features_df
        logger.info("–ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω—ã")
        
        # 10. –ë–ª–æ–∫ 11: –ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Å–ª–æ–π
        logger.info("=== –ë–õ–û–ö 11: –ö–ê–ù–û–ù–ò–ß–ï–°–ö–ò–ô –°–õ–û–ô ===")
        canonical_data = {
            "quotes": quotes_df,
            "book_top": book_df,
            "tape": tape_df,
            "nbbo": nbbo_df,
            "basis": basis_df,
            "features": features_df
        }
        run_canonical(canonical_data, config)
        results["canonical"] = canonical_data
        logger.info("–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–∏–π —Å–ª–æ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω")
        
        # 11. –ë–ª–æ–∫ 12: –î–µ—Ç–µ–∫—Ç–æ—Ä—ã
        logger.info("=== –ë–õ–û–ö 12: –î–ï–¢–ï–ö–¢–û–†–´ ===")
        lvb_detector = D1LiquidityVacuumBreak(config)
        detectors = [lvb_detector]
        detector_results = run_detectors(detectors, canonical_data)
        results["detectors"] = detector_results
        logger.info("–î–µ—Ç–µ–∫—Ç–æ—Ä—ã –∑–∞–ø—É—â–µ–Ω—ã")
        
        # 12. –ë–ª–æ–∫ 13: –°–∫–∞–Ω–µ—Ä
        logger.info("=== –ë–õ–û–ö 13: –°–ö–ê–ù–ï–† ===")
        scanner_results = run_scanner(config, detectors)
        results["scanner"] = scanner_results
        logger.info("–°–∫–∞–Ω–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        # 13. –ë–ª–æ–∫ 14: –ë—ç–∫—Ç–µ—Å—Ç
        logger.info("=== –ë–õ–û–ö 14: –ë–≠–ö–¢–ï–°–¢ ===")
        # TODO: –ü–æ–ª—É—á–∏—Ç—å —Å–æ–±—ã—Ç–∏—è –∏–∑ –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤
        events_df = pd.DataFrame()  # –ó–∞–≥–ª—É—à–∫–∞
        trades_df, metrics = run_backtest(events_df, quotes_df, config)
        results["backtest"] = {"trades": trades_df, "metrics": metrics}
        logger.info("–ë—ç–∫—Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        # 14. –ë–ª–æ–∫ 15: –≠–∫—Å–ø–æ—Ä—Ç —Ä–∞–∑–º–µ—Ç–∫–∏
        logger.info("=== –ë–õ–û–ö 15: –≠–ö–°–ü–û–†–¢ –†–ê–ó–ú–ï–¢–ö–ò ===")
        export_data(events_df, config)
        results["export"] = {"status": "completed"}
        logger.info("–≠–∫—Å–ø–æ—Ä—Ç —Ä–∞–∑–º–µ—Ç–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        logger.info("üéâ –í–°–Ø –¶–ï–ü–û–ß–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ü–µ–ø–æ—á–∫–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        raise
    
    return results

def run_test_pipeline(config_dir: str = "configs") -> Dict[str, any]:
    """–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–π —Ü–µ–ø–æ—á–∫–∏ (—Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –±–ª–æ–∫–∏)"""
    logger = logging.getLogger(__name__)
    logger.info("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–π —Ü–µ–ø–æ—á–∫–∏...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = load_config(config_dir)
    setup_logging(config)
    
    results = {}
    
    try:
        # –ë–ª–æ–∫ 02: –ò–º–ø–æ—Ä—Ç —Å—ã—Ä—å—è
        logger.info("=== –ë–õ–û–ö 02: –ò–ú–ü–û–†–¢ –°–´–†–¨–Ø ===")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
        import_data = {
            "data_paths": [],
            "start_time": None,
            "end_time": None
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º –∏–∑ sources.yaml
        if "sources" in config:
            sources = config["sources"]
            for market_type in ["spot", "futures"]:
                if market_type in sources:
                    for exchange in sources[market_type]:
                        for data_type in ["trades", "depth"]:
                            if data_type in sources[market_type][exchange]:
                                import_data["data_paths"].append(sources[market_type][exchange][data_type])
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(import_data['data_paths'])} –ø—É—Ç–µ–π –∫ –¥–∞–Ω–Ω—ã–º")
        
        trades_df, depth_df = import_raw_data(import_data, config)
        results["import"] = {"trades": trades_df, "depth": depth_df}
        
        # –ë–ª–æ–∫ 04: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏
        logger.info("=== –ë–õ–û–ö 04: –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –í–†–ï–ú–ï–ù–ò ===")
        synced_trades, synced_depth = run_time_sync(trades_df, depth_df, config)
        results["sync"] = {"trades": synced_trades, "depth": synced_depth}
        
        # –ë–ª–æ–∫ 05: –õ—É—á—à–∏–µ —Ü–µ–Ω—ã
        logger.info("=== –ë–õ–û–ö 05: –õ–£–ß–®–ò–ï –¶–ï–ù–´ ===")
        quotes_df = run_best_prices(synced_depth, config)
        results["quotes"] = quotes_df
        
        logger.info("‚úÖ –¢–µ—Å—Ç–æ–≤–∞—è —Ü–µ–ø–æ—á–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–æ–≤–æ–π —Ü–µ–ø–æ—á–∫–µ: {e}")
        raise
    
    return results

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤–æ–π —Ü–µ–ø–æ—á–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    results = run_test_pipeline()
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(results)} –±–ª–æ–∫–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
