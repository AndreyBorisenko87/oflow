"""
–ë–ª–æ–∫ 06: –¢–æ–ø-–∑–æ–Ω–∞ –∫–Ω–∏–≥–∏
–ü–æ–º–µ—Ç–∏—Ç—å —É—Ä–æ–≤–Ω–∏ 0‚Ä¶N —Ç–∏–∫–æ–≤ –∏ —Å—á–∏—Ç–∞—Ç—å –≥–ª—É–±–∏–Ω—É/–∏–∑–º–µ–Ω–µ–Ω–∏—è size/add/del
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

def analyze_top_levels(
    depth_df: pd.DataFrame,
    top_levels: int = 10,
    tick_width: float = 0.01
) -> pd.DataFrame:
    """
    –ê–Ω–∞–ª–∏–∑ —Ç–æ–ø-—É—Ä–æ–≤–Ω–µ–π order book —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ —Ç–∏–∫–∞–º
    
    Args:
        depth_df: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ depth –¥–∞–Ω–Ω—ã–µ
        top_levels: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø-—É—Ä–æ–≤–Ω–µ–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        tick_width: –®–∏—Ä–∏–Ω–∞ —Ç–∏–∫–∞ –≤ –µ–¥–∏–Ω–∏—Ü–∞—Ö —Ü–µ–Ω—ã
        
    Returns:
        DataFrame —Å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–æ–ø-—É—Ä–æ–≤–Ω—è–º–∏
    """
    logger.info(f"–ê–Ω–∞–ª–∏–∑ —Ç–æ–ø-{top_levels} —É—Ä–æ–≤–Ω–µ–π order book...")
    
    if depth_df.empty:
        logger.warning("Depth DataFrame –ø—É—Å—Ç–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        return pd.DataFrame()
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
    depth_df = depth_df.copy()
    
    # 1. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –±–∏—Ä–∂–∞–º –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫–Ω–∞–º
    book_analysis = []
    
    for exchange in depth_df['exchange'].unique():
        ex_data = depth_df[depth_df['exchange'] == exchange]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫–Ω–∞–º (10–º—Å)
        tick_size_ns = 10 * 1_000_000  # 10–º—Å –≤ –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥–∞—Ö
        ex_data['time_bucket'] = (ex_data['ts_ns'] // tick_size_ns) * tick_size_ns
        
        for bucket_time in ex_data['time_bucket'].unique():
            bucket_data = ex_data[ex_data['time_bucket'] == bucket_time]
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ bid –∏ ask
            bids = bucket_data[bucket_data['side'] == 'bid']
            asks = bucket_data[bucket_data['side'] == 'ask']
            
            # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º bid —É—Ä–æ–≤–Ω–∏ (–æ—Ç –≤—ã—Å—à–µ–π —Ü–µ–Ω—ã)
            bid_levels = []
            if not bids.empty:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ü–µ–Ω–µ (—É–±—ã–≤–∞–Ω–∏–µ) –∏ –±–µ—Ä–µ–º —Ç–æ–ø-—É—Ä–æ–≤–Ω–∏
                sorted_bids = bids.sort_values('price', ascending=False)
                
                for i, (_, row) in enumerate(sorted_bids.head(top_levels).iterrows()):
                    if row['size'] > 0:  # –¢–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
                        level_info = {
                            'ts_ns': bucket_time,
                            'exchange': exchange,
                            'side': 'bid',
                            'level': i,  # 0 = best bid, 1 = second best, etc.
                            'price': row['price'],
                            'size': row['size'],
                            'time_bucket': bucket_time,  # –î–æ–±–∞–≤–ª—è–µ–º time_bucket
                            'price_tick': round(row['price'] / tick_width) * tick_width,  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ —Ç–∏–∫–∞
                            'level_depth': row['size'],  # –ì–ª—É–±–∏–Ω–∞ –Ω–∞ —ç—Ç–æ–º —É—Ä–æ–≤–Ω–µ
                            'cumulative_depth': sorted_bids.head(i + 1)['size'].sum()  # –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
                        }
                        bid_levels.append(level_info)
            
            # 3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º ask —É—Ä–æ–≤–Ω–∏ (–æ—Ç –Ω–∏–∑—à–µ–π —Ü–µ–Ω—ã)
            ask_levels = []
            if not asks.empty:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ü–µ–Ω–µ (–≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏–µ) –∏ –±–µ—Ä–µ–º —Ç–æ–ø-—É—Ä–æ–≤–Ω–∏
                sorted_asks = asks.sort_values('price', ascending=True)
                
                for i, (_, row) in enumerate(sorted_asks.head(top_levels).iterrows()):
                    if row['size'] > 0:  # –¢–æ–ª—å–∫–æ –∞–∫—Ç–∏–≤–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
                        level_info = {
                            'ts_ns': bucket_time,
                            'exchange': exchange,
                            'side': 'ask',
                            'level': i,  # 0 = best ask, 1 = second best, etc.
                            'price': row['price'],
                            'size': row['size'],
                            'time_bucket': bucket_time,  # –î–æ–±–∞–≤–ª—è–µ–º time_bucket
                            'price_tick': round(row['price'] / tick_width) * tick_width,  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –¥–æ —Ç–∏–∫–∞
                            'level_depth': row['size'],  # –ì–ª—É–±–∏–Ω–∞ –Ω–∞ —ç—Ç–æ–º —É—Ä–æ–≤–Ω–µ
                            'cumulative_depth': sorted_asks.head(i + 1)['size'].sum()  # –ù–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞
                        }
                        ask_levels.append(level_info)
            
            # 4. –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —É—Ä–æ–≤–Ω–∏ –≤ –æ–±—â–∏–π —Å–ø–∏—Å–æ–∫
            book_analysis.extend(bid_levels)
            book_analysis.extend(ask_levels)
    
    # 5. –°–æ–∑–¥–∞–µ–º DataFrame –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    if book_analysis:
        book_df = pd.DataFrame(book_analysis)
        book_df = book_df.sort_values(['ts_ns', 'exchange', 'side', 'level']).reset_index(drop=True)
        
        logger.info(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(book_df)} —É—Ä–æ–≤–Ω–µ–π order book")
        logger.info(f"–í—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω: {book_df['ts_ns'].min()} - {book_df['ts_ns'].max()}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏—Ä–∂–∞–º
        for exchange in book_df['exchange'].unique():
            ex_data = book_df[book_df['exchange'] == exchange]
            logger.info(f"  {exchange}: {len(ex_data)} —É—Ä–æ–≤–Ω–µ–π")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å—Ç–æ—Ä–æ–Ω–∞–º
            for side in ['bid', 'ask']:
                side_data = ex_data[ex_data['side'] == side]
                if not side_data.empty:
                    logger.info(f"    {side}: {len(side_data)} —É—Ä–æ–≤–Ω–µ–π, —Å—Ä–µ–¥–Ω—è—è –≥–ª—É–±–∏–Ω–∞ {side_data['level_depth'].mean():.2f}")
    else:
        book_df = pd.DataFrame()
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —É—Ä–æ–≤–Ω–∏ order book")
    
    return book_df

def track_changes(
    book_df: pd.DataFrame,
    depth_df: pd.DataFrame,
    min_depth_threshold: float = 0.0
) -> pd.DataFrame:
    """
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ order book (add/del/modify)
    
    Args:
        book_df: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ order book
        depth_df: –ò—Å—Ö–æ–¥–Ω—ã–µ depth –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        min_depth_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –≥–ª—É–±–∏–Ω—ã –¥–ª—è —É—á–µ—Ç–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        
    Returns:
        DataFrame —Å –æ—Ç—Å–ª–µ–∂–µ–Ω–Ω—ã–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
    """
    logger.info("–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ order book...")
    
    if book_df.empty or depth_df.empty:
        logger.warning("–û–¥–∏–Ω –∏–∑ DataFrame –ø—É—Å—Ç–æ–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π book_df")
        return book_df
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
    book_df = book_df.copy()
    
    # 1. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º depth –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –±–∏—Ä–∂–∞–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    depth_df = depth_df.copy()
    tick_size_ns = 10 * 1_000_000
    depth_df['time_bucket'] = (depth_df['ts_ns'] // tick_size_ns) * tick_size_ns
    
    # 2. –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    previous_state = {}
    
    # 3. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –æ–∫–Ω–∞–º
    changes_list = []
    
    for exchange in book_df['exchange'].unique():
        ex_book = book_df[book_df['exchange'] == exchange]
        ex_depth = depth_df[depth_df['exchange'] == exchange]
        
        for bucket_time in sorted(ex_book['time_bucket'].unique()):
            current_book = ex_book[ex_book['time_bucket'] == bucket_time]
            current_depth = ex_depth[ex_depth['time_bucket'] == bucket_time]
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è
            state_key = f"{exchange}_{bucket_time}"
            
            # 4. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ä–æ–≤–Ω—è
            for _, level_row in current_book.iterrows():
                if level_row['level_depth'] < min_depth_threshold:
                    continue
                
                # –ò—â–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ depth –¥–∞–Ω–Ω—ã—Ö
                level_changes = current_depth[
                    (current_depth['side'] == level_row['side']) &
                    (abs(current_depth['price'] - level_row['price']) < 0.001)  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ü–µ–Ω—ã
                ]
                
                change_info = {
                    'ts_ns': bucket_time,
                    'exchange': exchange,
                    'side': level_row['side'],
                    'level': level_row['level'],
                    'price': level_row['price'],
                    'current_size': level_row['level_depth'],
                    'price_tick': level_row['price_tick'],
                    'cumulative_depth': level_row['cumulative_depth']
                }
                
                # 5. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π
                if not level_changes.empty:
                    # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
                    size_changes = level_changes['size'].values
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –∏–∑–º–µ–Ω–µ–Ω–∏—è
                    if len(size_changes) == 1:
                        if size_changes[0] > 0:
                            change_info['change_type'] = 'add'
                            change_info['size_change'] = size_changes[0]
                        else:
                            change_info['change_type'] = 'delete'
                            change_info['size_change'] = abs(size_changes[0])
                    else:
                        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è - —Å—á–∏—Ç–∞–µ–º –∫–∞–∫ modify
                        change_info['change_type'] = 'modify'
                        change_info['size_change'] = sum(size_changes)
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è (size/–≤—Ä–µ–º—è)
                    if len(level_changes) > 1:
                        time_range = level_changes['ts_ns'].max() - level_changes['ts_ns'].min()
                        if time_range > 0:
                            change_info['change_speed'] = change_info['size_change'] / (time_range / 1_000_000_000)  # size/—Å–µ–∫
                        else:
                            change_info['change_speed'] = 0.0
                    else:
                        change_info['change_speed'] = 0.0
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ delta
                    change_info['delta_count'] = len(level_changes)
                    change_info['delta_sizes'] = size_changes.tolist()
                else:
                    # –ù–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ —ç—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ–∫–Ω–µ
                    change_info['change_type'] = 'stable'
                    change_info['size_change'] = 0.0
                    change_info['change_speed'] = 0.0
                    change_info['delta_count'] = 0
                    change_info['delta_sizes'] = []
                
                changes_list.append(change_info)
    
    # 6. –°–æ–∑–¥–∞–µ–º DataFrame —Å –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
    if changes_list:
        changes_df = pd.DataFrame(changes_list)
        changes_df = changes_df.sort_values(['ts_ns', 'exchange', 'side', 'level']).reset_index(drop=True)
        
        logger.info(f"–û—Ç—Å–ª–µ–∂–µ–Ω–æ {len(changes_df)} –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ order book")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∏–∑–º–µ–Ω–µ–Ω–∏–π
        change_types = changes_df['change_type'].value_counts()
        logger.info("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∏–∑–º–µ–Ω–µ–Ω–∏–π:")
        for change_type, count in change_types.items():
            logger.info(f"  {change_type}: {count}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏—Ä–∂–∞–º
        for exchange in changes_df['exchange'].unique():
            ex_changes = changes_df[changes_df['exchange'] == exchange]
            logger.info(f"  {exchange}: {len(ex_changes)} –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            
            # –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π
            avg_speed = ex_changes['change_speed'].mean()
            logger.info(f"    –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–π: {avg_speed:.2f} size/—Å–µ–∫")
    else:
        changes_df = pd.DataFrame()
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Å–ª–µ–¥–∏—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è")
    
    return changes_df

def calculate_book_metrics(
    book_df: pd.DataFrame,
    changes_df: pd.DataFrame
) -> pd.DataFrame:
    """
    –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ order book
    
    Args:
        book_df: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ order book
        changes_df: –û—Ç—Å–ª–µ–∂–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        
    Returns:
        DataFrame —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
    """
    logger.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ order book...")
    
    if book_df.empty:
        return book_df
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
    book_df = book_df.copy()
    
    # 1. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —É—Ä–æ–≤–Ω—è–º
    book_metrics = []
    
    for exchange in book_df['exchange'].unique():
        ex_book = book_df[book_df['exchange'] == exchange]
        
        for bucket_time in ex_book['time_bucket'].unique():
            bucket_book = ex_book[ex_book['time_bucket'] == bucket_time]
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ bid –∏ ask
            bids = bucket_book[bucket_book['side'] == 'bid']
            asks = bucket_book[bucket_book['side'] == 'ask']
            
            metrics = {
                'ts_ns': bucket_time,
                'exchange': exchange
            }
            
            # 2. –ú–µ—Ç—Ä–∏–∫–∏ bid —Å—Ç–æ—Ä–æ–Ω—ã
            if not bids.empty:
                metrics['bid_levels_count'] = len(bids)
                metrics['bid_total_depth'] = bids['level_depth'].sum()
                metrics['bid_avg_depth'] = bids['level_depth'].mean()
                metrics['bid_max_depth'] = bids['level_depth'].max()
                metrics['bid_depth_std'] = bids['level_depth'].std()
                
                # –ì–ª—É–±–∏–Ω–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º
                for i in range(min(5, len(bids))):  # –ü–µ—Ä–≤—ã–µ 5 —É—Ä–æ–≤–Ω–µ–π
                    level_data = bids[bids['level'] == i]
                    if not level_data.empty:
                        metrics[f'bid_level_{i}_depth'] = level_data.iloc[0]['level_depth']
                        metrics[f'bid_level_{i}_price'] = level_data.iloc[0]['price']
                    else:
                        metrics[f'bid_level_{i}_depth'] = 0.0
                        metrics[f'bid_level_{i}_price'] = 0.0
            else:
                # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ—Ç bid –¥–∞–Ω–Ω—ã—Ö
                metrics.update({
                    'bid_levels_count': 0, 'bid_total_depth': 0.0, 'bid_avg_depth': 0.0,
                    'bid_max_depth': 0.0, 'bid_depth_std': 0.0
                })
                for i in range(5):
                    metrics[f'bid_level_{i}_depth'] = 0.0
                    metrics[f'bid_level_{i}_price'] = 0.0
            
            # 3. –ú–µ—Ç—Ä–∏–∫–∏ ask —Å—Ç–æ—Ä–æ–Ω—ã
            if not asks.empty:
                metrics['ask_levels_count'] = len(asks)
                metrics['ask_total_depth'] = asks['level_depth'].sum()
                metrics['ask_avg_depth'] = asks['level_depth'].mean()
                metrics['ask_max_depth'] = asks['level_depth'].max()
                metrics['ask_depth_std'] = asks['level_depth'].std()
                
                # –ì–ª—É–±–∏–Ω–∞ –ø–æ —É—Ä–æ–≤–Ω—è–º
                for i in range(min(5, len(asks))):  # –ü–µ—Ä–≤—ã–µ 5 —É—Ä–æ–≤–Ω–µ–π
                    level_data = asks[asks['level'] == i]
                    if not level_data.empty:
                        metrics[f'ask_level_{i}_depth'] = level_data.iloc[0]['level_depth']
                        metrics[f'ask_level_{i}_price'] = level_data.iloc[0]['price']
                    else:
                        metrics[f'ask_level_{i}_depth'] = 0.0
                        metrics[f'ask_level_{i}_price'] = 0.0
            else:
                # –ó–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ—Ç ask –¥–∞–Ω–Ω—ã—Ö
                metrics.update({
                    'ask_levels_count': 0, 'ask_total_depth': 0.0, 'ask_avg_depth': 0.0,
                    'ask_max_depth': 0.0, 'ask_depth_std': 0.0
                })
                for i in range(5):
                    metrics[f'ask_level_{i}_depth'] = 0.0
                    metrics[f'ask_level_{i}_price'] = 0.0
            
            # 4. –°–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            if not bids.empty and not asks.empty:
                # –õ—É—á—à–∏–µ —Ü–µ–Ω—ã
                best_bid = bids[bids['level'] == 0]['price'].iloc[0] if not bids[bids['level'] == 0].empty else 0.0
                best_ask = asks[asks['level'] == 0]['price'].iloc[0] if not asks[asks['level'] == 0].empty else 0.0
                
                if best_bid > 0 and best_ask > 0:
                    metrics['spread'] = best_ask - best_bid
                    metrics['spread_rel'] = (best_ask - best_bid) / best_bid * 100
                    metrics['mid_price'] = (best_bid + best_ask) / 2
                else:
                    metrics['spread'] = 0.0
                    metrics['spread_rel'] = 0.0
                    metrics['mid_price'] = 0.0
                
                # –û–±—â–∞—è –≥–ª—É–±–∏–Ω–∞
                metrics['total_book_depth'] = metrics['bid_total_depth'] + metrics['ask_total_depth']
                metrics['depth_imbalance'] = abs(metrics['bid_total_depth'] - metrics['ask_total_depth']) / metrics['total_book_depth']
            else:
                metrics.update({
                    'spread': 0.0, 'spread_rel': 0.0, 'mid_price': 0.0,
                    'total_book_depth': 0.0, 'depth_imbalance': 0.0
                })
            
            book_metrics.append(metrics)
    
    # 5. –°–æ–∑–¥–∞–µ–º DataFrame —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
    if book_metrics:
        metrics_df = pd.DataFrame(book_metrics)
        metrics_df = metrics_df.sort_values(['ts_ns', 'exchange']).reset_index(drop=True)
        
        logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω–æ {len(metrics_df)} –º–µ—Ç—Ä–∏–∫ order book")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏—Ä–∂–∞–º
        for exchange in metrics_df['exchange'].unique():
            ex_metrics = metrics_df[metrics_df['exchange'] == exchange]
            logger.info(f"  {exchange}: {len(ex_metrics)} –º–µ—Ç—Ä–∏–∫")
            
            if 'spread' in ex_metrics.columns:
                avg_spread = ex_metrics['spread'].mean()
                logger.info(f"    –°—Ä–µ–¥–Ω–∏–π —Å–ø—Ä–µ–¥: {avg_spread:.4f}")
    else:
        metrics_df = pd.DataFrame()
        logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏")
    
    return metrics_df

def save_book_top(
    book_df: pd.DataFrame,
    changes_df: pd.DataFrame,
    metrics_df: pd.DataFrame,
    output_path: Path,
    config: Dict
) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–ø-–∑–æ–Ω—ã order book
    
    Args:
        book_df: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
        changes_df: –û—Ç—Å–ª–µ–∂–µ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        metrics_df: –í—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    """
    logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ order book –≤ {output_path}...")
    
    try:
        # 1. –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # 2. –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∂–∞—Ç–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        compression = config.get("export", {}).get("compression", "snappy")
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —É—Ä–æ–≤–Ω–∏
        if not book_df.empty:
            book_path = output_path / "book_levels.parquet"
            book_df.to_parquet(
                book_path,
                engine="pyarrow",
                compression=compression,
                index=False
            )
            logger.info(f"–£—Ä–æ–≤–Ω–∏ order book —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {len(book_df)} —Å—Ç—Ä–æ–∫")
        
        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        if not changes_df.empty:
            changes_path = output_path / "book_changes.parquet"
            changes_df.to_parquet(
                changes_path,
                engine="pyarrow",
                compression=compression,
                index=False
            )
            logger.info(f"–ò–∑–º–µ–Ω–µ–Ω–∏—è order book —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {len(changes_df)} —Å—Ç—Ä–æ–∫")
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        if not metrics_df.empty:
            metrics_path = output_path / "book_metrics.parquet"
            metrics_df.to_parquet(
                metrics_path,
                engine="pyarrow",
                compression=compression,
                index=False
            )
            logger.info(f"–ú–µ—Ç—Ä–∏–∫–∏ order book —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {len(metrics_df)} —Å—Ç—Ä–æ–∫")
        
        # 6. –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ order book —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_path}")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ order book: {e}")
        raise

def run_book_top(
    depth_df: pd.DataFrame,
    config: Dict,
    output_dir: Path = Path("../../../data/test_small/book_top")
) -> Dict[str, pd.DataFrame]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–ø-–∑–æ–Ω—ã order book
    
    Args:
        depth_df: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ depth –¥–∞–Ω–Ω—ã–µ
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
    """
    logger.info("–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–ø-–∑–æ–Ω—ã order book...")
    
    try:
        # 1. –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        top_levels = config.get("order_book", {}).get("top_levels", 10)
        tick_width = config.get("order_book", {}).get("tick_width", 0.01)
        min_depth_threshold = config.get("order_book", {}).get("depth_threshold", 0.0)
        
        logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞: top_levels={top_levels}, tick_width={tick_width}")
        
        # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ø-—É—Ä–æ–≤–Ω–∏
        logger.info("–ê–Ω–∞–ª–∏–∑ —Ç–æ–ø-—É—Ä–æ–≤–Ω–µ–π order book...")
        book_df = analyze_top_levels(depth_df, top_levels, tick_width)
        
        if book_df.empty:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —É—Ä–æ–≤–Ω–∏ order book, –∑–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É")
            return {}
        
        # 3. –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
        logger.info("–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ order book...")
        changes_df = track_changes(book_df, depth_df, min_depth_threshold)
        
        # 4. –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        logger.info("–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ order book...")
        metrics_df = calculate_book_metrics(book_df, changes_df)
        
        # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        logger.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞...")
        save_book_top(book_df, changes_df, metrics_df, output_dir, config)
        
        # 6. –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        logger.info("=== –ò–¢–û–ì–ò –ê–ù–ê–õ–ò–ó–ê ORDER BOOK ===")
        logger.info(f"–ò—Å—Ö–æ–¥–Ω—ã–µ depth –∑–∞–ø–∏—Å–∏: {len(depth_df):,}")
        logger.info(f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —É—Ä–æ–≤–Ω–µ–π: {len(book_df):,}")
        
        if not changes_df.empty:
            logger.info(f"–û—Ç—Å–ª–µ–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {len(changes_df):,}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º –∏–∑–º–µ–Ω–µ–Ω–∏–π
            change_types = changes_df['change_type'].value_counts()
            for change_type, count in change_types.items():
                logger.info(f"  {change_type}: {count}")
        
        if not metrics_df.empty:
            logger.info(f"–í—ã—á–∏—Å–ª–µ–Ω–æ –º–µ—Ç—Ä–∏–∫: {len(metrics_df):,}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏—Ä–∂–∞–º
        for exchange in book_df['exchange'].unique():
            ex_levels = book_df[book_df['exchange'] == exchange]
            logger.info(f"  {exchange}: {len(ex_levels)} —É—Ä–æ–≤–Ω–µ–π")
        
        logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ —Ç–æ–ø-–∑–æ–Ω—ã order book –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
        
        # 7. –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {
            'book_levels': book_df,
            'book_changes': changes_df,
            'book_metrics': metrics_df
        }
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ order book: {e}")
        raise
    
    return results


if __name__ == "__main__":
    """–ó–∞–ø—É—Å–∫ –±–ª–æ–∫–∞ 06 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    import pandas as pd
    import logging
    import sys
    import os
    import time
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ base_block
    sys.path.append(os.path.dirname(__file__))
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
    
    print("üß™ –¢–ï–°–¢ –ë–õ–û–ö–ê 06: Book Top")
    print("=" * 50)
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        depth_df = pd.read_parquet("../../../data/test_small/book_top_small.parquet")
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:")
        print(f"   - Depth: {len(depth_df)} —Å—Ç—Ä–æ–∫")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –±–∏—Ä–∂–∏ —É –Ω–∞—Å –µ—Å—Ç—å
        if not depth_df.empty:
            exchanges = depth_df['exchange'].unique()
            print(f"   - –ë–∏—Ä–∂–∏ –≤ depth: {exchanges}")
            print(f"   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∏—Ä–∂: {len(exchanges)}")
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ order book
        config = {
            'order_book': {
                'top_levels': 5,  # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–ø-5 —É—Ä–æ–≤–Ω–µ–π
                'tick_width': 0.01,  # –®–∏—Ä–∏–Ω–∞ —Ç–∏–∫–∞
                'depth_threshold': 0.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –≥–ª—É–±–∏–Ω—ã
            }
        }
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫ 06
        print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫ 06: –ê–Ω–∞–ª–∏–∑ —Ç–æ–ø-–∑–æ–Ω—ã order book...")
        start_time = time.time()
        
        results = run_book_top(depth_df, config)
        
        execution_time = time.time() - start_time
        
        print(f"‚úÖ –ë–ª–æ–∫ 06 –≤—ã–ø–æ–ª–Ω–µ–Ω –∑–∞ {execution_time:.2f} —Å–µ–∫—É–Ω–¥!")
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if 'book_levels' in results:
            book_levels = results['book_levels']
            print(f"   - –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —É—Ä–æ–≤–Ω–µ–π: {len(book_levels)}")
            
            if not book_levels.empty:
                print(f"   - –ë–∏—Ä–∂–∏ –≤ —É—Ä–æ–≤–Ω—è—Ö: {book_levels['exchange'].unique()}")
                print(f"   - –°—Ç–æ—Ä–æ–Ω—ã: {book_levels['side'].unique()}")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –±–∏—Ä–∂–∞–º
                for exchange in book_levels['exchange'].unique():
                    ex_levels = book_levels[book_levels['exchange'] == exchange]
                    print(f"   - {exchange}: {len(ex_levels)} —É—Ä–æ–≤–Ω–µ–π")
        
        if 'book_changes' in results:
            book_changes = results['book_changes']
            print(f"   - –û—Ç—Å–ª–µ–∂–µ–Ω–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {len(book_changes)}")
        
        if 'book_metrics' in results:
            book_metrics = results['book_metrics']
            print(f"   - –í—ã—á–∏—Å–ª–µ–Ω–æ –º–µ—Ç—Ä–∏–∫: {len(book_metrics)}")
        
        print("‚úÖ –ë–ª–æ–∫ 06 —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
