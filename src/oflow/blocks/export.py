"""
Ð‘Ð»Ð¾Ðº 15: Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ¸
Ð’Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ° ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹/ÑÐ´ÐµÐ»Ð¾Ðº Ð² CSV Ð´Ð»Ñ TradingView/ATAS
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

def export_to_csv(
    data_df: pd.DataFrame,
    output_path: Path,
    format_type: str = "tradingview",
    config: Dict = None
) -> None:
    """Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð² CSV Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ°Ð¼Ð¸"""
    logger.info(f"ðŸ“¤ Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð² CSV ({format_type})...")
    
    if data_df.empty:
        logger.warning("âš ï¸ DataFrame Ð¿ÑƒÑÑ‚Ð¾Ð¹, ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½")
        return
    
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°
        export_config = config.get('export', {}) if config else {}
        encoding = export_config.get('encoding', 'utf-8')
        separator = export_config.get('separator', ',')
        decimal_separator = export_config.get('decimal_separator', '.')
        date_format = export_config.get('date_format', '%Y-%m-%d %H:%M:%S')
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ ÐµÑÐ»Ð¸ Ð½Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°
        export_df = data_df.copy()
        
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ (Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼ Ñ‚Ð¾Ñ‡ÐºÑƒ Ð½Ð° Ð·Ð°Ð¿ÑÑ‚ÑƒÑŽ ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾)
        if decimal_separator != '.':
            numeric_columns = export_df.select_dtypes(include=[np.number]).columns
            for col in numeric_columns:
                export_df[col] = export_df[col].astype(str).str.replace('.', decimal_separator)
        
        # Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² CSV
        export_df.to_csv(
            output_path,
            index=False,
            sep=separator,
            encoding=encoding,
            date_format=date_format,
            float_format='%.6f'
        )
        
        # Ð›Ð¾Ð³Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ„Ð°Ð¹Ð»Ðµ
        file_size_kb = output_path.stat().st_size / 1024
        logger.info(f"âœ… CSV ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½: {output_path}")
        logger.info(f"ðŸ“Š Ð Ð°Ð·Ð¼ÐµÑ€ Ñ„Ð°Ð¹Ð»Ð°: {file_size_kb:.1f} KB")
        logger.info(f"ðŸ“ˆ ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ ÑÑ‚Ñ€Ð¾Ðº: {len(export_df)}")
        
        # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°Ð¼
        logger.info(f"ðŸ”¤ ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸: {', '.join(export_df.columns)}")
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ CSV: {e}")
        raise

def format_for_tradingview(events_df: pd.DataFrame) -> pd.DataFrame:
    """Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ TradingView"""
    logger.info("Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ TradingView...")
    
    if events_df.empty:
        return events_df
    
    # TODO: Ð ÐµÐ°Ð»Ð¸Ð·Ð¾Ð²Ð°Ñ‚ÑŒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ TradingView
    # 1. Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº
    # 2. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
    # 3. Ð¦ÐµÐ½Ð¾Ð²Ñ‹Ðµ ÑƒÑ€Ð¾Ð²Ð½Ð¸
    
    # Ð—Ð°Ð³Ð»ÑƒÑˆÐºÐ°
    tv_df = events_df.copy()
    tv_df['time'] = pd.to_datetime(tv_df['ts_ns'], unit='ns')
    
    return tv_df

def format_for_atas(events_df: pd.DataFrame, config: Dict = None) -> pd.DataFrame:
    """Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ATAS"""
    logger.info("ðŸ“Š Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ ATAS...")
    
    if events_df.empty:
        logger.warning("âš ï¸ DataFrame Ð¿ÑƒÑÑ‚Ð¾Ð¹, Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½Ð¾")
        return events_df
    
    try:
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ATAS
        atas_config = config.get('atas', {}) if config else {}
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð¿Ð¸ÑŽ Ð´Ð»Ñ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
        atas_df = events_df.copy()
        
        # 1. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð´Ð»Ñ ATAS
        if 'ts_ns' in atas_df.columns:
            atas_df['DateTime'] = pd.to_datetime(atas_df['ts_ns'], unit='ns')
            atas_df['Date'] = atas_df['DateTime'].dt.strftime('%m/%d/%Y')
            atas_df['Time'] = atas_df['DateTime'].dt.strftime('%H:%M:%S')
        
        # 2. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ†ÐµÐ½Ñ‹
        if 'price_level' in atas_df.columns:
            atas_df['Price'] = atas_df['price_level'].round(6)
        elif 'mid' in atas_df.columns:
            atas_df['Price'] = atas_df['mid'].round(6)
        
        # 3. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚Ð¾Ðº ATAS
        atas_df['Marker'] = atas_df.apply(_create_atas_marker, axis=1)
        
        # 4. Ð¦Ð²ÐµÑ‚Ð¾Ð²Ð°Ñ ÑÑ…ÐµÐ¼Ð° ATAS
        atas_df['Color'] = atas_df.apply(_create_atas_color, axis=1)
        
        # 5. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚Ð¸Ð¿Ð° Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°
        if 'pattern_type' in atas_df.columns:
            atas_df['Pattern'] = atas_df['pattern_type'].str.upper()
            atas_df['PatternCode'] = atas_df['pattern_type'].str[:3].str.upper()
        
        # 6. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
        if 'confidence' in atas_df.columns:
            atas_df['Confidence'] = atas_df['confidence'].round(3)
            atas_df['ConfidenceLevel'] = atas_df['confidence'].apply(
                lambda x: 'HIGH' if x >= 0.8 else 'MEDIUM' if x >= 0.6 else 'LOW'
            )
        
        # 7. Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð»Ñ Ð´Ð»Ñ ATAS
        if 'volume_ratio' in atas_df.columns:
            atas_df['VolumeRatio'] = atas_df['volume_ratio'].round(2)
        
        if 'exchange' in atas_df.columns:
            atas_df['Exchange'] = atas_df['exchange'].str.upper()
        
        # 8. Ð’Ñ‹Ð±Ð¾Ñ€ Ð¸ Ð¿ÐµÑ€ÐµÐ¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð´Ð»Ñ ATAS
        atas_columns = {
            'Date': 'Date',
            'Time': 'Time',
            'Price': 'Price',
            'Marker': 'Marker',
            'Color': 'Color',
            'Pattern': 'Pattern',
            'Confidence': 'Confidence',
            'VolumeRatio': 'VolumeRatio',
            'Exchange': 'Exchange'
        }
        
        # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸
        existing_columns = {k: v for k, v in atas_columns.items() if k in atas_df.columns}
        atas_df = atas_df[list(existing_columns.keys())].rename(columns=existing_columns)
        
        # 9. Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        if 'Date' in atas_df.columns and 'Time' in atas_df.columns:
            atas_df = atas_df.sort_values(['Date', 'Time']).reset_index(drop=True)
        
        logger.info(f"âœ… Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ ATAS Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾: {len(atas_df)} ÑÑ‚Ñ€Ð¾Ðº")
        logger.info(f"ðŸ”¤ ÐšÐ¾Ð»Ð¾Ð½ÐºÐ¸: {', '.join(atas_df.columns)}")
        
        return atas_df
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¸ Ð´Ð»Ñ ATAS: {e}")
        raise

def _create_tv_marker(row: pd.Series) -> str:
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚ÐºÐ¸ Ð´Ð»Ñ TradingView"""
    try:
        pattern = row.get('pattern_type', '').upper()
        confidence = row.get('confidence', 0.0)
        
        # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸ Ð¿Ð¾ Ñ‚Ð¸Ð¿Ñƒ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°
        if 'liquidity_vacuum_break' in pattern:
            base_marker = 'LVB'
        elif 'iceberg_fade' in pattern:
            base_marker = 'ICB'
        elif 'stop_run' in pattern:
            base_marker = 'STP'
        elif 'momentum' in pattern:
            base_marker = 'MOM'
        else:
            base_marker = 'PTN'
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
        if confidence >= 0.8:
            strength = 'S'
        elif confidence >= 0.6:
            strength = 'M'
        else:
            strength = 'W'
        
        return f"{base_marker}_{strength}"
        
    except Exception:
        return "PTN_M"

def _create_atas_marker(row: pd.Series) -> str:
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼ÐµÑ‚ÐºÐ¸ Ð´Ð»Ñ ATAS"""
    try:
        pattern = row.get('pattern_type', '').upper()
        confidence = row.get('confidence', 0.0)
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸ Ð´Ð»Ñ ATAS
        if 'liquidity_vacuum_break' in pattern:
            if confidence >= 0.8:
                return 'LVB_HIGH'
            elif confidence >= 0.6:
                return 'LVB_MED'
            else:
                return 'LVB_LOW'
        elif 'iceberg_fade' in pattern:
            if confidence >= 0.8:
                return 'ICB_HIGH'
            elif confidence >= 0.6:
                return 'ICB_MED'
            else:
                return 'ICB_LOW'
        elif 'stop_run' in pattern:
            if confidence >= 0.8:
                return 'STP_HIGH'
            elif confidence >= 0.6:
                return 'STP_MED'
            else:
                return 'STP_LOW'
        elif 'momentum' in pattern:
            if confidence >= 0.8:
                return 'MOM_HIGH'
            elif confidence >= 0.6:
                return 'MOM_MED'
            else:
                return 'MOM_LOW'
        else:
            return 'PATTERN'
            
    except Exception:
        return "PATTERN"

def _create_atas_color(row: pd.Series) -> str:
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ†Ð²ÐµÑ‚Ð° Ð´Ð»Ñ ATAS"""
    try:
        pattern = row.get('pattern_type', '')
        confidence = row.get('confidence', 0.0)
        
        # Ð¦Ð²ÐµÑ‚Ð° Ð¿Ð¾ Ñ‚Ð¸Ð¿Ñƒ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°
        if 'liquidity_vacuum_break' in pattern:
            base_color = 'RED'
        elif 'iceberg_fade' in pattern:
            base_color = 'BLUE'
        elif 'stop_run' in pattern:
            base_color = 'GREEN'
        elif 'momentum' in pattern:
            base_color = 'YELLOW'
        else:
            base_color = 'WHITE'
        
        # Ð˜Ð½Ñ‚ÐµÐ½ÑÐ¸Ð²Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
        if confidence >= 0.8:
            intensity = 'BRIGHT'
        elif confidence >= 0.6:
            intensity = 'NORMAL'
        else:
            intensity = 'DIM'
        
        return f"{base_color}_{intensity}"
        
    except Exception:
        return "WHITE_NORMAL"

def run_export(
    events_df: pd.DataFrame,
    config: Dict,
    output_dir: Path = Path("data/export")
) -> None:
    """ÐžÑÐ½Ð¾Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ¸"""
    logger.info("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð° Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ¸...")
    
    try:
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð²Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        if events_df.empty:
            logger.warning("âš ï¸ ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°")
            return
        
        logger.info(f"ðŸ“Š Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ {len(events_df)} ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹")
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð»Ñ TradingView
        logger.info("ðŸ“ˆ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ TradingView...")
        tv_df = format_for_tradingview(events_df, config)
        if not tv_df.empty:
            tv_path = output_dir / "marks_tradingview.csv"
            export_to_csv(tv_df, tv_path, "tradingview", config)
            logger.info(f"âœ… TradingView ÑÐºÑÐ¿Ð¾Ñ€Ñ‚: {tv_path}")
        
        # 2. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚ Ð´Ð»Ñ ATAS
        logger.info("ðŸ“Š ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ ATAS...")
        atas_df = format_for_atas(events_df, config)
        if not atas_df.empty:
            atas_path = output_dir / "marks_atas.csv"
            export_to_csv(atas_df, atas_path, "atas", config)
            logger.info(f"âœ… ATAS ÑÐºÑÐ¿Ð¾Ñ€Ñ‚: {atas_path}")
        
        # 3. ÐžÐ±Ñ‰Ð¸Ð¹ CSV ÑÐºÑÐ¿Ð¾Ñ€Ñ‚
        logger.info("ðŸ“‹ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð¾Ð±Ñ‰ÐµÐ³Ð¾ CSV...")
        general_path = output_dir / "marks_general.csv"
        export_to_csv(events_df, general_path, "general", config)
        logger.info(f"âœ… ÐžÐ±Ñ‰Ð¸Ð¹ CSV ÑÐºÑÐ¿Ð¾Ñ€Ñ‚: {general_path}")
        
        # 4. Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ²Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
        logger.info("ðŸ“ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ²Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°...")
        _create_export_summary(events_df, output_dir, config)
        
        # 5. Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ð°Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°
        logger.info("=== Ð˜Ð¢ÐžÐ“Ð˜ Ð­ÐšÐ¡ÐŸÐžÐ Ð¢Ð ===")
        logger.info(f"ðŸ“Š Ð’ÑÐµÐ³Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹: {len(events_df)}")
        
        if 'pattern_type' in events_df.columns:
            pattern_counts = events_df['pattern_type'].value_counts()
            logger.info("ðŸ“ˆ Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°Ð¼:")
            for pattern, count in pattern_counts.items():
                logger.info(f"  {pattern}: {count}")
        
        if 'confidence' in events_df.columns:
            avg_confidence = events_df['confidence'].mean()
            logger.info(f"ðŸŽ¯ Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {avg_confidence:.3f}")
        
        if 'exchange' in events_df.columns:
            exchange_counts = events_df['exchange'].value_counts()
            logger.info("ðŸ¢ Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ Ð±Ð¸Ñ€Ð¶Ð°Ð¼:")
            for exchange, count in exchange_counts.items():
                logger.info(f"  {exchange}: {count}")
        
        logger.info(f"ðŸ“ Ð¤Ð°Ð¹Ð»Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {output_dir}")
        logger.info("âœ… Ð­ÐºÑÐ¿Ð¾Ñ€Ñ‚ Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ¸ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½!")
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ¸: {e}")
        import traceback
        traceback.print_exc()
        raise

def _create_export_summary(events_df: pd.DataFrame, output_dir: Path, config: Dict) -> None:
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ²Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð° Ð¿Ð¾ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ñƒ"""
    try:
        summary_path = output_dir / "export_summary.txt"
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=== Ð¡Ð’ÐžÐ”ÐÐ«Ð™ ÐžÐ¢Ð§Ð•Ð¢ ÐŸÐž Ð­ÐšÐ¡ÐŸÐžÐ Ð¢Ð£ ===\n\n")
            f.write(f"Ð”Ð°Ñ‚Ð° ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°: {pd.Timestamp.now()}\n")
            f.write(f"Ð’ÑÐµÐ³Ð¾ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹: {len(events_df)}\n\n")
            
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¿Ð°Ñ‚Ñ‚ÐµÑ€Ð½Ð°Ð¼
            if 'pattern_type' in events_df.columns:
                f.write("=== Ð ÐÐ¡ÐŸÐ Ð•Ð”Ð•Ð›Ð•ÐÐ˜Ð• ÐŸÐž ÐŸÐÐ¢Ð¢Ð•Ð ÐÐÐœ ===\n")
                pattern_counts = events_df['pattern_type'].value_counts()
                for pattern, count in pattern_counts.items():
                    percentage = (count / len(events_df)) * 100
                    f.write(f"{pattern}: {count} ({percentage:.1f}%)\n")
                f.write("\n")
            
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð±Ð¸Ñ€Ð¶Ð°Ð¼
            if 'exchange' in events_df.columns:
                f.write("=== Ð ÐÐ¡ÐŸÐ Ð•Ð”Ð•Ð›Ð•ÐÐ˜Ð• ÐŸÐž Ð‘Ð˜Ð Ð–ÐÐœ ===\n")
                exchange_counts = events_df['exchange'].value_counts()
                for exchange, count in exchange_counts.items():
                    percentage = (count / len(events_df)) * 100
                    f.write(f"{exchange}: {count} ({percentage:.1f}%)\n")
                f.write("\n")
            
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
            if 'confidence' in events_df.columns:
                f.write("=== Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ Ð£Ð’Ð•Ð Ð•ÐÐÐžÐ¡Ð¢Ð˜ ===\n")
                f.write(f"Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {events_df['confidence'].mean():.3f}\n")
                f.write(f"ÐœÐµÐ´Ð¸Ð°Ð½Ð½Ð°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {events_df['confidence'].median():.3f}\n")
                f.write(f"ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {events_df['confidence'].min():.3f}\n")
                f.write(f"ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ: {events_df['confidence'].max():.3f}\n")
                
                # Ð Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑƒÑ€Ð¾Ð²Ð½ÑÐ¼ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸
                high_conf = len(events_df[events_df['confidence'] >= 0.8])
                med_conf = len(events_df[(events_df['confidence'] >= 0.6) & (events_df['confidence'] < 0.8)])
                low_conf = len(events_df[events_df['confidence'] < 0.6])
                
                f.write(f"Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ (â‰¥0.8): {high_conf} ({high_conf/len(events_df)*100:.1f}%)\n")
                f.write(f"Ð¡Ñ€ÐµÐ´Ð½ÑÑ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ (0.6-0.8): {med_conf} ({med_conf/len(events_df)*100:.1f}%)\n")
                f.write(f"ÐÐ¸Ð·ÐºÐ°Ñ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ (<0.6): {low_conf} ({low_conf/len(events_df)*100:.1f}%)\n")
                f.write("\n")
            
            # Ð¡Ñ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ° Ð¿Ð¾ Ð¾Ð±ÑŠÐµÐ¼Ñƒ
            if 'volume_ratio' in events_df.columns:
                f.write("=== Ð¡Ð¢ÐÐ¢Ð˜Ð¡Ð¢Ð˜ÐšÐ ÐŸÐž ÐžÐ‘ÐªÐ•ÐœÐ£ ===\n")
                f.write(f"Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐ¼Ð°: {events_df['volume_ratio'].mean():.2f}\n")
                f.write(f"ÐœÐµÐ´Ð¸Ð°Ð½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐ¼Ð°: {events_df['volume_ratio'].median():.2f}\n")
                f.write(f"ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÑÐ¾Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ðµ Ð¾Ð±ÑŠÐµÐ¼Ð°: {events_df['volume_ratio'].max():.2f}\n")
                f.write("\n")
            
            # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½
            if 'ts_ns' in events_df.columns:
                f.write("=== Ð’Ð Ð•ÐœÐ•ÐÐÐžÐ™ Ð”Ð˜ÐÐŸÐÐ—ÐžÐ ===\n")
                start_time = pd.to_datetime(events_df['ts_ns'].min(), unit='ns')
                end_time = pd.to_datetime(events_df['ts_ns'].max(), unit='ns')
                f.write(f"ÐÐ°Ñ‡Ð°Ð»Ð¾: {start_time}\n")
                f.write(f"ÐšÐ¾Ð½ÐµÑ†: {end_time}\n")
                f.write(f"ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ: {end_time - start_time}\n")
                f.write("\n")
            
            # Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð¾ Ñ„Ð°Ð¹Ð»Ð°Ñ…
            f.write("=== Ð­ÐšÐ¡ÐŸÐžÐ Ð¢Ð˜Ð ÐžÐ’ÐÐÐÐ«Ð• Ð¤ÐÐ™Ð›Ð« ===\n")
            f.write("marks_tradingview.csv - Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ TradingView\n")
            f.write("marks_atas.csv - Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ ATAS\n")
            f.write("marks_general.csv - ÐžÐ±Ñ‰Ð¸Ð¹ CSV ÑÐºÑÐ¿Ð¾Ñ€Ñ‚\n")
            f.write("export_summary.txt - Ð­Ñ‚Ð¾Ñ‚ Ð¾Ñ‚Ñ‡ÐµÑ‚\n")
        
        logger.info(f"âœ… Ð¡Ð²Ð¾Ð´Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ‡ÐµÑ‚ ÑÐ¾Ð·Ð´Ð°Ð½: {summary_path}")
        
    except Exception as e:
        logger.error(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ð¸ ÑÐ²Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°: {e}")
        # ÐÐµ Ð¿Ñ€ÐµÑ€Ñ‹Ð²Ð°ÐµÐ¼ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°
